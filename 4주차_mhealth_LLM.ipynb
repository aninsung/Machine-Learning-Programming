{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "mount_file_id": "1zuxEYYE042sMxdqVJ8h9zvuAopvnsQST",
      "authorship_tag": "ABX9TyN+4ur0npJggpKwFMl/05a5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aninsung/Machine-Learning-Programming/blob/main/4%EC%A3%BC%EC%B0%A8_mhealth_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (오늘 실습과제)\n",
        "\n",
        "Mhealth dataset으로 인간행동 분류하기\n",
        "\n",
        "일단 데이터 읽어서 subject 번호가 컬럼면에 포함된 통합 data frame 만들고 CNN, LSTM, CNN-LSTM 해보기.\n",
        "\n",
        "1. LLM(sLLM)을 제외한 어떤 모델을 써도 가능. 단 라이브러리 import 불가. 모델의 풀 소스가 있어야 함.\n",
        "\n",
        " 2. 10명을 1+2, 3+4, 4+5,.... 5개그룹으로 나눠 2명씩 테스트 데이터로 하면서 cross validation.\n",
        "\n",
        " 3. 데이터 증대는 안됨.\n",
        "\n",
        "4. 오직 모델로만 성능 향상\n",
        "\n",
        "5. 상위 30%씩 차등.\n",
        "\n",
        "6. 성적에 반영\n",
        "\n",
        "7. 11월15일까지. Github게시\n",
        "\n",
        "교차 평가로 평균 F1 기준.\n",
        "\n",
        "8. 본인이 완벽하게 소스 및 모델을 설명할 수 있어야 함. GPT를 쓰던 뭘 쓰던 그건 상관안함. 재현성이 보장되어야 함.\n",
        "--------------------------------------------------------------------------\n",
        "--------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "Kzbk4hbgc2Rx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터설명\n",
        "📌 Dataset Summary\n",
        "\n",
        "Subjects: 10명 (다양한 프로필의 자원자)\n",
        "\n",
        "Activities: 12개\n",
        "\n",
        "Sensors: 3개 (가슴, 오른쪽 손목, 왼쪽 발목 → elastic strap으로 고정)\n",
        "\n",
        "측정 정보:\n",
        "\n",
        "Acceleration (가속도)\n",
        "\n",
        "Gyroscope (회전율)\n",
        "\n",
        "Magnetometer (자기장 방향)\n",
        "\n",
        "Chest sensor: 2-lead ECG 추가 (활동 인식에는 사용 안 함, 향후 연구용)\n",
        "\n",
        "Sampling Rate: 50 Hz\n",
        "\n",
        "환경: Out-of-lab, 제약 없이 자유롭게 활동 수행 (단, 최선을 다해 실행)\n",
        "\n",
        "📌 Activity Set (12 classes)\n",
        "\n",
        "정적 활동: Standing still, Sitting, Lying down\n",
        "\n",
        "일상/이동 활동: Walking, Climbing stairs, Cycling\n",
        "\n",
        "운동/역동적 활동: Jogging, Running, Jump front & back\n",
        "\n",
        "반복 동작: Waist bends, Arm elevation, Knees bending\n",
        "\n",
        "📌 특징\n",
        "\n",
        "ECG 포함: 운동 중 심전도 기록 → 부정맥, 심박수 모니터링, 운동 효과 분석 가능\n",
        "\n",
        "다양성 확보:\n",
        "\n",
        "동작 강도 차이 (예: Sitting vs. Running)\n",
        "\n",
        "속도 차이 (예: Walking vs. Jogging)\n",
        "\n",
        "다른 신체 부위 동작 (예: Arm elevation vs. Knees bending)\n",
        "\n",
        "실생활 반영: 실제 환경에서 수행되어 일반화 성능 높음"
      ],
      "metadata": {
        "id": "NYZGoj3bciYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM, TimeDistributed, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy import stats\n",
        "import os\n",
        "\n",
        "\n",
        "DATASET_BASE_PATH = \"/content/drive/MyDrive/Colab Notebooks/mhealth+dataset/MHEALTHDATASET\""
      ],
      "metadata": {
        "id": "NE8bgggoCZ73"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10개 주제의 모든 데이터를 로드하여 하나의 데이터프레임으로 통합\n",
        "all_dfs = []\n",
        "column_names = [\n",
        "    'chest_acc_x', 'chest_acc_y', 'chest_acc_z', 'ecg_lead1', 'ecg_lead2', 'left_ankle_acc_x',\n",
        "    'left_ankle_acc_y', 'left_ankle_acc_z', 'left_ankle_gyro_x', 'left_ankle_gyro_y',\n",
        "    'left_ankle_gyro_z', 'left_ankle_mag_x', 'left_ankle_mag_y', 'left_ankle_mag_z',\n",
        "    'right_wrist_acc_x', 'right_wrist_acc_y', 'right_wrist_acc_z', 'right_wrist_gyro_x',\n",
        "    'right_wrist_gyro_y', 'right_wrist_gyro_z', 'right_wrist_mag_x', 'right_wrist_mag_y',\n",
        "    'right_wrist_mag_z', 'activity_label'\n",
        "]\n",
        "\n",
        "for i in range(1, 11):\n",
        "    file_path = os.path.join(DATASET_BASE_PATH, f\"mHealth_subject{i}.log\")\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, sep='\\s+', header=None, names=column_names)\n",
        "        df['subject'] = i\n",
        "        all_dfs.append(df)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"오류: {file_path}를 찾을 수 없습니다.\")\n",
        "        all_dfs = []\n",
        "        break\n",
        "\n",
        "if all_dfs:\n",
        "    mhealth_df = pd.concat(all_dfs, ignore_index=True)\n",
        "    print(\"데이터 로드 및 통합 완료.\")\n",
        "    print(f\"전체 데이터 형태: {mhealth_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCJIO6UXD0Sc",
        "outputId": "7ec3cda7-69f3-4559-f902-fe744e84dbf5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:14: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:14: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-937467728.py:14: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  df = pd.read_csv(file_path, sep='\\s+', header=None, names=column_names)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5-겹 교차검증을 위해 피험자 기준으로 데이터를 나누고 스케일링\n",
        "scaled_data_folds = []\n",
        "if 'mhealth_df' in locals():\n",
        "    feature_cols = mhealth_df.columns.drop(['activity_label', 'subject'])\n",
        "    label_col = 'activity_label'\n",
        "    num_classes = mhealth_df[label_col].nunique()\n",
        "    test_subject_pairs = [(i, i + 1) for i in range(1, 11, 2)]\n",
        "\n",
        "    for test_subjects in test_subject_pairs:\n",
        "        train_df = mhealth_df[~mhealth_df['subject'].isin(test_subjects)].copy()\n",
        "        test_df = mhealth_df[mhealth_df['subject'].isin(test_subjects)].copy()\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        train_df.loc[:, feature_cols] = scaler.fit_transform(train_df[feature_cols])\n",
        "        test_df.loc[:, feature_cols] = scaler.transform(test_df[feature_cols])\n",
        "\n",
        "        scaled_data_folds.append({'train_df': train_df, 'test_df': test_df})\n",
        "\n",
        "    print(f\"총 {len(scaled_data_folds)}개 폴드의 데이터 분할 및 스케일링 완료.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQxgWevxD2cv",
        "outputId": "862e0af7-9959-4cbd-969d-b6e68f3382bc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "## 통합 데이터프레임 정보:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 343195 entries, 6656 to 1213645\n",
            "Data columns (total 23 columns):\n",
            " #   Column              Non-Null Count   Dtype  \n",
            "---  ------              --------------   -----  \n",
            " 0   chest_acc_x         343195 non-null  float64\n",
            " 1   chest_acc_y         343195 non-null  float64\n",
            " 2   chest_acc_z         343195 non-null  float64\n",
            " 3   left_ankle_acc_x    343195 non-null  float64\n",
            " 4   left_ankle_acc_y    343195 non-null  float64\n",
            " 5   left_ankle_acc_z    343195 non-null  float64\n",
            " 6   left_ankle_gyro_x   343195 non-null  float64\n",
            " 7   left_ankle_gyro_y   343195 non-null  float64\n",
            " 8   left_ankle_gyro_z   343195 non-null  float64\n",
            " 9   left_ankle_mag_x    343195 non-null  float64\n",
            " 10  left_ankle_mag_y    343195 non-null  float64\n",
            " 11  left_ankle_mag_z    343195 non-null  float64\n",
            " 12  right_wrist_acc_x   343195 non-null  float64\n",
            " 13  right_wrist_acc_y   343195 non-null  float64\n",
            " 14  right_wrist_acc_z   343195 non-null  float64\n",
            " 15  right_wrist_gyro_x  343195 non-null  float64\n",
            " 16  right_wrist_gyro_y  343195 non-null  float64\n",
            " 17  right_wrist_gyro_z  343195 non-null  float64\n",
            " 18  right_wrist_mag_x   343195 non-null  float64\n",
            " 19  right_wrist_mag_y   343195 non-null  float64\n",
            " 20  right_wrist_mag_z   343195 non-null  float64\n",
            " 21  activity_label      343195 non-null  int64  \n",
            " 22  subject             343195 non-null  int64  \n",
            "dtypes: float64(21), int64(2)\n",
            "memory usage: 62.8 MB\n",
            "\n",
            "## 통합 데이터프레임 샘플:\n",
            "      chest_acc_x  chest_acc_y  chest_acc_z  left_ankle_acc_x  \\\n",
            "6656      -9.7788      0.55690      1.19750            2.6493   \n",
            "6657      -9.7733      0.27880      0.73036            2.4157   \n",
            "6658      -9.8609      0.11561      0.79988            2.3865   \n",
            "6659      -9.7409      0.17652      0.88957            2.3758   \n",
            "6660      -9.7821      0.21637      0.90368            2.3239   \n",
            "\n",
            "      left_ankle_acc_y  left_ankle_acc_z  left_ankle_gyro_x  \\\n",
            "6656           -9.4517           0.37683           -0.20965   \n",
            "6657           -9.5306           0.40179           -0.20965   \n",
            "6658           -9.5991           0.48141           -0.20037   \n",
            "6659           -9.5997           0.42919           -0.20037   \n",
            "6660           -9.5406           0.40038           -0.20037   \n",
            "\n",
            "      left_ankle_gyro_y  left_ankle_gyro_z  left_ankle_mag_x  ...  \\\n",
            "6656           -0.88931           -0.50884           0.56366  ...   \n",
            "6657           -0.88931           -0.50884           0.56810  ...   \n",
            "6658           -0.86867           -0.50688           0.21110  ...   \n",
            "6659           -0.86867           -0.50688           0.21565  ...   \n",
            "6660           -0.86867           -0.50688           0.56810  ...   \n",
            "\n",
            "      right_wrist_acc_y  right_wrist_acc_z  right_wrist_gyro_x  \\\n",
            "6656            -9.0618             1.8177           -0.058824   \n",
            "6657            -9.2048             1.5189           -0.058824   \n",
            "6658            -9.1945             1.5507           -0.058824   \n",
            "6659            -9.1746             1.5413           -0.078431   \n",
            "6660            -9.2039             1.6127           -0.078431   \n",
            "\n",
            "      right_wrist_gyro_y  right_wrist_gyro_z  right_wrist_mag_x  \\\n",
            "6656            -0.93429            -0.34483           0.355370   \n",
            "6657            -0.93429            -0.34483           0.719910   \n",
            "6658            -0.93429            -0.34483           0.355370   \n",
            "6659            -0.93429            -0.34052           0.357180   \n",
            "6660            -0.93429            -0.34052          -0.001887   \n",
            "\n",
            "      right_wrist_mag_y  right_wrist_mag_z  activity_label  subject  \n",
            "6656           -0.37003           -0.35020               0        1  \n",
            "6657            0.17803            0.37363               0        1  \n",
            "6658           -0.37003           -0.35020               0        1  \n",
            "6659           -0.18858           -0.35198               0        1  \n",
            "6660           -0.18867           -0.72017               0        1  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 스케일링된 데이터를 윈도우 형태로 변환하여 최종 학습 데이터셋 생성\n",
        "prepared_data = []\n",
        "if 'scaled_data_folds' in locals():\n",
        "    feature_cols = mhealth_df.columns.drop(['activity_label', 'subject'])\n",
        "    label_col = 'activity_label'\n",
        "\n",
        "    for fold in scaled_data_folds:\n",
        "        train_df = fold['train_df']\n",
        "        test_df = fold['test_df']\n",
        "\n",
        "        X_train, y_train = [], []\n",
        "        for i in range(0, len(train_df) - 128, 64):\n",
        "            X_train.append(train_df[feature_cols].iloc[i: i + 128].values)\n",
        "            y_train.append(stats.mode(train_df[label_col].iloc[i: i + 128], keepdims=True)[0][0])\n",
        "\n",
        "        X_test, y_test = [], []\n",
        "        for i in range(0, len(test_df) - 128, 64):\n",
        "            X_test.append(test_df[feature_cols].iloc[i: i + 128].values)\n",
        "            y_test.append(stats.mode(test_df[label_col].iloc[i: i + 128], keepdims=True)[0][0])\n",
        "\n",
        "        prepared_data.append({\n",
        "            'X_train': np.array(X_train), 'y_train': np.array(y_train),\n",
        "            'X_test': np.array(X_test), 'y_test': np.array(y_test)\n",
        "        })\n",
        "\n",
        "    print(f\"총 {len(prepared_data)}개 폴드의 윈도우 생성 완료.\")"
      ],
      "metadata": {
        "id": "MHN2yNDkD357"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성된 데이터의 형태 확인\n",
        "if prepared_data:\n",
        "    X_train_sample = prepared_data[0]['X_train']\n",
        "    y_train_sample = prepared_data[0]['y_train']\n",
        "\n",
        "    print(\"X_train shape:\", X_train_sample.shape)\n",
        "    print(\"y_train shape:\", y_train_sample.shape)"
      ],
      "metadata": {
        "id": "Ylfs-X4AD5HS"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_windows(data, feature_cols, label_col):\n",
        "    X, y = [], []\n",
        "    for i in range(0, len(data) - 128, 64):\n",
        "        # 특징 데이터 추출\n",
        "        X.append(data[feature_cols].iloc[i: i + 128].values)\n",
        "        # 윈도우 내에서 가장 빈번한 값으로 레이블 결정\n",
        "        y.append(stats.mode(data[label_col].iloc[i: i + 128], keepdims=True)[0][0])\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlteVFSpD6B2",
        "outputId": "c76193ee-fa54-4bb7-9b5c-2948ca302363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Fold 1/5 (Test Subjects: (1, 2)) =====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if prepared_data:\n",
        "    accuracies = []\n",
        "    for i, fold_data in enumerate(prepared_data):\n",
        "        X_train, y_train = fold_data['X_train'], fold_data['y_train']\n",
        "        X_test, y_test = fold_data['X_test'], fold_data['y_test']\n",
        "\n",
        "        input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "\n",
        "        model = Sequential([\n",
        "            LSTM(100, input_shape=input_shape),\n",
        "            Dropout(0.5),\n",
        "            Dense(100, activation='relu'),\n",
        "            Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        model.fit(X_train, y_train, epochs=20, batch_size=64, verbose=0)\n",
        "        loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "        accuracies.append(accuracy)\n",
        "        print(f\"LSTM | Fold {i+1}/5 | Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    final_accuracies['lstm'] = np.mean(accuracies)"
      ],
      "metadata": {
        "id": "ZsTd7N5JExbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if prepared_data:\n",
        "    accuracies = []\n",
        "    for i, fold_data in enumerate(prepared_data):\n",
        "        X_train, y_train = fold_data['X_train'], fold_data['y_train']\n",
        "        X_test, y_test = fold_data['X_test'], fold_data['y_test']\n",
        "\n",
        "        X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1], X_train.shape[2]))\n",
        "        X_test_reshaped = X_test.reshape((X_test.shape[0], 1, X_test.shape[1], X_test.shape[2]))\n",
        "\n",
        "        input_shape = (None, X_train.shape[1], X_train.shape[2])\n",
        "\n",
        "        model = Sequential([\n",
        "            TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=input_shape),\n",
        "            TimeDistributed(MaxPooling1D(pool_size=2)),\n",
        "            TimeDistributed(Flatten()),\n",
        "            LSTM(100),\n",
        "            Dropout(0.5),\n",
        "            Dense(100, activation='relu'),\n",
        "            Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        model.fit(X_train_reshaped, y_train, epochs=20, batch_size=64, verbose=0)\n",
        "        loss, accuracy = model.evaluate(X_test_reshaped, y_test, verbose=0)\n",
        "        accuracies.append(accuracy)\n",
        "        print(f\"CNN-LSTM | Fold {i+1}/5 | Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    final_accuracies['cnn-lstm'] = np.mean(accuracies)"
      ],
      "metadata": {
        "id": "7Tvanz0uI9VT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== 최종 모델 평균 정확도 비교 =====\")\n",
        "if 'final_accuracies' in locals() and final_accuracies:\n",
        "    for model_name, avg_accuracy in final_accuracies.items():\n",
        "        print(f\"{model_name.upper():<10} : {avg_accuracy:.4f}\")\n",
        "else:\n",
        "    print(\"훈련된 모델이 없습니다.\")"
      ],
      "metadata": {
        "id": "S2IBWjhRI-L6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}