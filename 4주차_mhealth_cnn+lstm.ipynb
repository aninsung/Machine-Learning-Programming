{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "mount_file_id": "https://github.com/aninsung/Machine-Learning-Programming/blob/main/4%EC%A3%BC%EC%B0%A8_mhealth_cnn%2Blstm.ipynb",
      "authorship_tag": "ABX9TyMRI0opquU960Bs/Xa1s146",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aninsung/Machine-Learning-Programming/blob/main/4%EC%A3%BC%EC%B0%A8_mhealth_cnn%2Blstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (ì˜¤ëŠ˜ ì‹¤ìŠµê³¼ì œ)\n",
        "\n",
        "Mhealth datasetìœ¼ë¡œ ì¸ê°„í–‰ë™ ë¶„ë¥˜í•˜ê¸°\n",
        "\n",
        "ì¼ë‹¨ ë°ì´í„° ì½ì–´ì„œ subject ë²ˆí˜¸ê°€ ì»¬ëŸ¼ë©´ì— í¬í•¨ëœ í†µí•© data frame ë§Œë“¤ê³  CNN, LSTM, CNN-LSTM í•´ë³´ê¸°.\n",
        "\n",
        "1. LLM(sLLM)ì„ ì œì™¸í•œ ì–´ë–¤ ëª¨ë¸ì„ ì¨ë„ ê°€ëŠ¥. ë‹¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ë¶ˆê°€. ëª¨ë¸ì˜ í’€ ì†ŒìŠ¤ê°€ ìˆì–´ì•¼ í•¨.\n",
        "\n",
        " 2. 10ëª…ì„ 1+2, 3+4, 4+5,.... 5ê°œê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ  2ëª…ì”© í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ í•˜ë©´ì„œ cross validation.\n",
        "\n",
        " 3. ë°ì´í„° ì¦ëŒ€ëŠ” ì•ˆë¨.\n",
        "\n",
        "4. ì˜¤ì§ ëª¨ë¸ë¡œë§Œ ì„±ëŠ¥ í–¥ìƒ\n",
        "\n",
        "5. ìƒìœ„ 30%ì”© ì°¨ë“±.\n",
        "\n",
        "6. ì„±ì ì— ë°˜ì˜\n",
        "\n",
        "7. 11ì›”15ì¼ê¹Œì§€. Githubê²Œì‹œ\n",
        "\n",
        "êµì°¨ í‰ê°€ë¡œ í‰ê·  F1 ê¸°ì¤€.\n",
        "\n",
        "8. ë³¸ì¸ì´ ì™„ë²½í•˜ê²Œ ì†ŒìŠ¤ ë° ëª¨ë¸ì„ ì„¤ëª…í•  ìˆ˜ ìˆì–´ì•¼ í•¨. GPTë¥¼ ì“°ë˜ ë­˜ ì“°ë˜ ê·¸ê±´ ìƒê´€ì•ˆí•¨. ì¬í˜„ì„±ì´ ë³´ì¥ë˜ì–´ì•¼ í•¨.\n",
        "--------------------------------------------------------------------------\n",
        "--------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "Kzbk4hbgc2Rx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ë°ì´í„°ì„¤ëª…\n",
        "ğŸ“Œ Dataset Summary\n",
        "\n",
        "Subjects: 10ëª… (ë‹¤ì–‘í•œ í”„ë¡œí•„ì˜ ìì›ì)\n",
        "\n",
        "Activities: 12ê°œ\n",
        "\n",
        "Sensors: 3ê°œ (ê°€ìŠ´, ì˜¤ë¥¸ìª½ ì†ëª©, ì™¼ìª½ ë°œëª© â†’ elastic strapìœ¼ë¡œ ê³ ì •)\n",
        "\n",
        "ì¸¡ì • ì •ë³´:\n",
        "\n",
        "Acceleration (ê°€ì†ë„)\n",
        "\n",
        "Gyroscope (íšŒì „ìœ¨)\n",
        "\n",
        "Magnetometer (ìê¸°ì¥ ë°©í–¥)\n",
        "\n",
        "Chest sensor: 2-lead ECG ì¶”ê°€ (í™œë™ ì¸ì‹ì—ëŠ” ì‚¬ìš© ì•ˆ í•¨, í–¥í›„ ì—°êµ¬ìš©)\n",
        "\n",
        "Sampling Rate: 50 Hz\n",
        "\n",
        "í™˜ê²½: Out-of-lab, ì œì•½ ì—†ì´ ììœ ë¡­ê²Œ í™œë™ ìˆ˜í–‰ (ë‹¨, ìµœì„ ì„ ë‹¤í•´ ì‹¤í–‰)\n",
        "\n",
        "ğŸ“Œ Activity Set (12 classes)\n",
        "\n",
        "ì •ì  í™œë™: Standing still, Sitting, Lying down\n",
        "\n",
        "ì¼ìƒ/ì´ë™ í™œë™: Walking, Climbing stairs, Cycling\n",
        "\n",
        "ìš´ë™/ì—­ë™ì  í™œë™: Jogging, Running, Jump front & back\n",
        "\n",
        "ë°˜ë³µ ë™ì‘: Waist bends, Arm elevation, Knees bending\n",
        "\n",
        "ğŸ“Œ íŠ¹ì§•\n",
        "\n",
        "ECG í¬í•¨: ìš´ë™ ì¤‘ ì‹¬ì „ë„ ê¸°ë¡ â†’ ë¶€ì •ë§¥, ì‹¬ë°•ìˆ˜ ëª¨ë‹ˆí„°ë§, ìš´ë™ íš¨ê³¼ ë¶„ì„ ê°€ëŠ¥\n",
        "\n",
        "ë‹¤ì–‘ì„± í™•ë³´:\n",
        "\n",
        "ë™ì‘ ê°•ë„ ì°¨ì´ (ì˜ˆ: Sitting vs. Running)\n",
        "\n",
        "ì†ë„ ì°¨ì´ (ì˜ˆ: Walking vs. Jogging)\n",
        "\n",
        "ë‹¤ë¥¸ ì‹ ì²´ ë¶€ìœ„ ë™ì‘ (ì˜ˆ: Arm elevation vs. Knees bending)\n",
        "\n",
        "ì‹¤ìƒí™œ ë°˜ì˜: ì‹¤ì œ í™˜ê²½ì—ì„œ ìˆ˜í–‰ë˜ì–´ ì¼ë°˜í™” ì„±ëŠ¥ ë†’ìŒ"
      ],
      "metadata": {
        "id": "NYZGoj3bciYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "# 1. íŒŒì¼ ë¦¬ìŠ¤íŠ¸\n",
        "files = sorted(glob.glob(\"/content/drive/MyDrive/Colab Notebooks/mhealth+dataset/MHEALTHDATASET/mHealth_subject*.log\"))\n",
        "\n",
        "# 2. ì»¬ëŸ¼ ì •ì˜\n",
        "columns = [\n",
        "    \"chest_acc_x\",\"chest_acc_y\",\"chest_acc_z\",\n",
        "    \"ecg_1\",\"ecg_2\",\n",
        "    \"chest_gyro_x\",\"chest_gyro_y\",\"chest_gyro_z\",\n",
        "    \"chest_mag_x\",\"chest_mag_y\",\"chest_mag_z\",\n",
        "    \"ankle_acc_x\",\"ankle_acc_y\",\"ankle_acc_z\",\n",
        "    \"ankle_gyro_x\",\"ankle_gyro_y\",\"ankle_gyro_z\",\n",
        "    \"ankle_mag_x\",\"ankle_mag_y\",\"ankle_mag_z\",\n",
        "    \"wrist_acc_x\",\"wrist_acc_y\",\"wrist_acc_z\",\n",
        "    \"label\"\n",
        "]\n",
        "\n",
        "# 3. ê° íŒŒì¼ ì½ì–´ì„œ subject_id ì¶”ê°€\n",
        "dfs = []\n",
        "for i, file in enumerate(files, start=1):\n",
        "    df = pd.read_csv(file, sep=\"\\s+\", header=None)\n",
        "    df.columns = columns\n",
        "    df[\"subject_id\"] = i\n",
        "    dfs.append(df)\n",
        "\n",
        "# 4. í†µí•© DataFrame\n",
        "data = pd.concat(dfs, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "D1Aa1xO4LxT5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "outputId": "edebb9c4-f664-4194-cf6f-e88e7f08b13b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:24: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:24: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-4155912323.py:24: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  df = pd.read_csv(file, sep=\"\\s+\", header=None)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4155912323.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\s+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"subject_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/codecs.py\u001b[0m in \u001b[0;36mgetstate\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_windows(df, frame_size=100, hop_size=50):\n",
        "    X, y = [], []\n",
        "    data_values = df.drop([\"label\", \"subject_id\"], axis=1).values\n",
        "    labels = df[\"label\"].values\n",
        "    for i in range(0, len(data_values)-frame_size, hop_size):\n",
        "        X.append(data_values[i:i+frame_size])\n",
        "        y.append(labels[i+frame_size-1])  # ë§ˆì§€ë§‰ ì‹œì  label\n",
        "    return np.array(X), np.array(y)\n"
      ],
      "metadata": {
        "id": "md-2RokFUIAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38726812"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Add, GlobalAveragePooling1D, Dense, Dropout\n",
        "\n",
        "def residual_block(x, filters, kernel_size=3, stride=1):\n",
        "    shortcut = x\n",
        "    # ì²« ë²ˆì§¸ Conv\n",
        "    x = Conv1D(filters, kernel_size, strides=stride, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    # ë‘ ë²ˆì§¸ Conv\n",
        "    x = Conv1D(filters, kernel_size, strides=1, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    # shortcut ì°¨ì› ë§ì¶”ê¸°\n",
        "    if shortcut.shape[-1] != filters or stride != 1:\n",
        "        shortcut = Conv1D(filters, 1, strides=stride, padding='same')(shortcut)\n",
        "        shortcut = BatchNormalization()(shortcut)\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def build_resnet(timesteps, n_features, n_classes):\n",
        "    inputs = Input(shape=(timesteps, n_features))\n",
        "\n",
        "    x = Conv1D(64, 7, strides=2, padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Residual blocks\n",
        "    x = residual_block(x, 64)\n",
        "    x = residual_block(x, 128, stride=2)\n",
        "    x = residual_block(x, 256, stride=2)\n",
        "\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "# ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n",
        "acc_list = []\n",
        "loss_list = []\n",
        "f1_list = []\n",
        "\n",
        "subjects = np.arange(1,11)\n",
        "folds = [(subjects[i], subjects[i+1]) for i in range(0,10,2)]\n",
        "\n",
        "# Define parameters for windowing and model\n",
        "timesteps = 100\n",
        "n_features = data.drop([\"label\", \"subject_id\"], axis=1).shape[1]\n",
        "n_classes = data[\"label\"].nunique()\n",
        "\n",
        "for fold_idx, test_subjects in enumerate(folds, start=1):\n",
        "    # Train/Test ë¶„ë¦¬\n",
        "    test_data = data[data[\"subject_id\"].isin(test_subjects)]\n",
        "    train_data = data[~data[\"subject_id\"].isin(test_subjects)]\n",
        "\n",
        "    # ìœˆë„ìš° ìƒì„±\n",
        "    X_train, y_train = create_windows(train_data, frame_size=timesteps, hop_size=50)\n",
        "    X_test, y_test = create_windows(test_data, frame_size=timesteps, hop_size=50)\n",
        "\n",
        "    print(f\"\\n=== Fold {fold_idx}: Test subjects {test_subjects} ===\")\n",
        "    print(\"Samples:\", X_train.shape[0], \"(train)\", X_test.shape[0], \"(test)\")\n",
        "\n",
        "    # ëª¨ë¸\n",
        "    model = build_resnet(timesteps, n_features, n_classes)\n",
        "    # í•™ìŠµ\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=1)\n",
        "\n",
        "    # í‰ê°€\n",
        "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # F1-score ê³„ì‚° (ë‹¤ì¤‘ í´ë˜ìŠ¤ëŠ” 'macro' ì¶”ì²œ)\n",
        "    f1 = f1_score(y_test, y_pred_classes, average='macro')\n",
        "\n",
        "    print(f\"Test Accuracy: {acc:.4f}, Loss: {loss:.4f}, F1-score: {f1:.4f}\")\n",
        "\n",
        "    # ë¦¬ìŠ¤íŠ¸ì— ì €ì¥\n",
        "    acc_list.append(acc)\n",
        "    loss_list.append(loss)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "# Cross-validation í‰ê· \n",
        "print(\"\\n=== Cross-validation Average ===\")\n",
        "print(f\"Average Accuracy: {np.mean(acc_list):.4f}\")\n",
        "print(f\"Average Loss: {np.mean(loss_list):.4f}\")\n",
        "print(f\"Average F1-score: {np.mean(f1_list):.4f}\")"
      ],
      "metadata": {
        "id": "Rzs_f6pL2CmY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}